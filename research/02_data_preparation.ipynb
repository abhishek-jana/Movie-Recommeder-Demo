{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\abhis\\\\Desktop\\\\MLProjects\\\\Movie Recommender'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"../\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating the entity (return type of a function) like configbox, and the example below\n",
    "# same return from config.yaml\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataPreparationConfig:\n",
    "    root_dir: Path\n",
    "    source_URL: str\n",
    "    cache_dir: Path\n",
    "    movies_data: Path\n",
    "    links_data: Path\n",
    "    ratings_data: Path\n",
    "    # final_data_path: Path\n",
    "    ratings_data_path: Path\n",
    "    movies_data_path: Path\n",
    "    unique_category_path: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MovieRecommender.constants import *\n",
    "from MovieRecommender.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update congiuration manager cat configuration.py\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "            self,\n",
    "            config_filepath = CONFIG_FILE_PATH,\n",
    "            params_filepath = PARAMS_FILE_PATH):\n",
    "        \n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_data_preparation_config(self) -> DataPreparationConfig:\n",
    "        data_preparation = self.config.data_preparation\n",
    "        final_data_dir = os.path.dirname(data_preparation.ratings_data_path)\n",
    "        create_directories([Path(data_preparation.root_dir),\n",
    "                            Path(data_preparation.cache_dir),\n",
    "                            Path(final_data_dir)\n",
    "                            ])\n",
    "        folder = self.config.data_ingestion.source_URL.split('/')[-1].split('.zip')[0]\n",
    "        movies_data = os.path.join(self.config.data_ingestion.unzip_dir, folder, 'movies.csv')\n",
    "        links_data = os.path.join(self.config.data_ingestion.unzip_dir,folder, 'links.csv')\n",
    "        ratings_data = os.path.join(self.config.data_ingestion.unzip_dir, folder,'ratings.csv')\n",
    "        data_preparation_config = DataPreparationConfig(\n",
    "            root_dir =Path(data_preparation.root_dir),\n",
    "            source_URL = data_preparation.source_URL,\n",
    "            cache_dir = Path(data_preparation.cache_dir),\n",
    "            movies_data = Path(movies_data),\n",
    "            links_data = Path(links_data),\n",
    "            ratings_data = Path(ratings_data),\n",
    "            # final_data_path = Path(data_preparation.final_data_path),\n",
    "            ratings_data_path = Path(data_preparation.ratings_data_path),\n",
    "            movies_data_path = Path(data_preparation.movies_data_path), \n",
    "            unique_category_path = Path(data_preparation.unique_category_path)\n",
    "        )\n",
    "    \n",
    "        return data_preparation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Update components\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib\n",
    "import urllib.request as request\n",
    "from MovieRecommender.constants import *\n",
    "from MovieRecommender.logging import logger\n",
    "# from MovieRecommender.utils.common import get_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source_URL = \"https://api.themoviedb.org/3/movie/\"\n",
    "# movie_id = 894\n",
    "\n",
    "# print(f'{source_URL}{movie_id}?api_key={API_KEY}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreparation:\n",
    "    def __init__(self, config: DataPreparationConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def get_df(self, data_path):\n",
    "        \"\"\"\n",
    "        Read a CSV file into a pandas DataFrame.\n",
    "\n",
    "        Args:\n",
    "            data_path (str): File path of the CSV file.\n",
    "\n",
    "        Returns:\n",
    "            pandas.DataFrame: DataFrame containing the data from the CSV file.\n",
    "        \"\"\"\n",
    "        df = pd.read_csv(data_path)\n",
    "        return df\n",
    "\n",
    "    def drop_nan_vals(self, df):\n",
    "        \"\"\"\n",
    "        Drop rows with missing values (NaN) from a DataFrame.\n",
    "\n",
    "        Args:\n",
    "            df (pandas.DataFrame): DataFrame to drop missing values from.\n",
    "\n",
    "        Returns:\n",
    "            None (modifies df in-place).\n",
    "        \"\"\"\n",
    "        return df.dropna(inplace=True)\n",
    "    \n",
    "    def drop_cols(self, df, columns):\n",
    "        \"\"\"\n",
    "        Drop specified columns from a DataFrame.\n",
    "\n",
    "        Args:\n",
    "            df (pandas.DataFrame): DataFrame to drop columns from.\n",
    "            columns (list): List of column names to drop.\n",
    "\n",
    "        Returns:\n",
    "            None (modifies df in-place).\n",
    "        \"\"\"\n",
    "        return df.drop(columns = columns, inplace = True)\n",
    "\n",
    "    def merge_df(self, df1, df2, col_name):\n",
    "        \"\"\"\n",
    "        Merge two DataFrames based on a common column.\n",
    "\n",
    "        Args:\n",
    "            df1 (pandas.DataFrame): First DataFrame to merge.\n",
    "            df2 (pandas.DataFrame): Second DataFrame to merge.\n",
    "            col_name (str): Name of the common column to merge on.\n",
    "\n",
    "        Returns:\n",
    "            pandas.DataFrame: Merged DataFrame.\n",
    "        \"\"\"\n",
    "        merged_df =  df1.merge(df2, on = col_name)\n",
    "        return merged_df\n",
    "    def merge_df_with_index(self, df1, df2):\n",
    "        \"\"\"\n",
    "        Merge two DataFrames based on their index.\n",
    "\n",
    "        Args:\n",
    "            df1 (pandas.DataFrame): First DataFrame to merge.\n",
    "            df2 (pandas.DataFrame): Second DataFrame to merge.\n",
    "\n",
    "        Returns:\n",
    "            pandas.DataFrame: Merged DataFrame.\n",
    "        \"\"\"\n",
    "        merged_df =  pd.merge(df1, df2, left_index=True, right_index=True)\n",
    "        return merged_df\n",
    "    \n",
    "    def rename_cols(self, df,columns):\n",
    "        \"\"\"rename columns\n",
    "\n",
    "        Args:\n",
    "            df (pandas): pandas dataframe\n",
    "            columns (dict): key val with key -> column to be replaced\n",
    "                            val -> new name\n",
    "        Returns:\n",
    "            df: modified df\n",
    "        \"\"\"\n",
    "        return df.rename(columns = columns, inplace=True)\n",
    "    def reindex_columns(self, df, column_order):\n",
    "        \"\"\"\n",
    "        Reindex the columns of a DataFrame according to the desired order.\n",
    "\n",
    "        Args:\n",
    "            df (pandas.DataFrame): The DataFrame to reindex.\n",
    "            column_order (list): The desired order of columns.\n",
    "\n",
    "        Returns:\n",
    "            pandas.DataFrame: The DataFrame with reindexed columns.\n",
    "        \"\"\"\n",
    "        # Reindex the columns\n",
    "        df = df.reindex(columns=column_order)\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def unique_genres(self,df):\n",
    "        \"\"\"\n",
    "        the total number of unique genres in a DataFrame's 'genres' column.\n",
    "\n",
    "        Args:\n",
    "            df (pandas.DataFrame): DataFrame containing a 'genres' column.\n",
    "\n",
    "        Returns:\n",
    "            int: Total number of unique genres.\n",
    "\n",
    "        Usage:\n",
    "            df = pd.DataFrame({'genres': [['Action', 'Adventure'], ['Comedy', 'Romance'], ['Drama']]})\n",
    "            total_genres = count_unique_genres(df)\n",
    "            print(total_genres)  # Output: 4\n",
    "        \"\"\"\n",
    "        genre_column = df['genres']\n",
    "        unique_genres = set()\n",
    "\n",
    "        for genres_list in genre_column:\n",
    "            unique_genres.update(genres_list)\n",
    "\n",
    "        # total_genres = len(unique_genres)\n",
    "        return list(unique_genres)\n",
    "\n",
    "    \n",
    "    def save_dataframe_to_csv(self,df, path_to_file):\n",
    "        \"\"\"\n",
    "        Save a DataFrame to a specified folder as a CSV file.\n",
    "\n",
    "        Args:\n",
    "            df (pandas.DataFrame): The DataFrame to save.\n",
    "            file_name (str): The name of the CSV file (including the extension).\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "\n",
    "        \n",
    "        # Save the DataFrame to CSV\n",
    "        df.to_csv(path_to_file, index=False)\n",
    "        \n",
    "        logger.info(f\"DataFrame saved successfully in '{path_to_file}'.\")\n",
    "\n",
    "    def save_dataframe_to_parquet(self,df, path_to_file):\n",
    "        \"\"\"\n",
    "        Save a DataFrame to a specified folder as a parquet file.\n",
    "\n",
    "        Args:\n",
    "            df (pandas.DataFrame): The DataFrame to save.\n",
    "            file_name (str): The name of the CSV file (including the extension).\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "\n",
    "        \n",
    "        # Save the DataFrame to CSV\n",
    "        df.to_parquet(path_to_file)\n",
    "    def save_dataframe_to_feather(self,df, path_to_file):\n",
    "        \"\"\"\n",
    "        Save a DataFrame to a specified folder as a parquet file.\n",
    "\n",
    "        Args:\n",
    "            df (pandas.DataFrame): The DataFrame to save.\n",
    "            file_name (str): The name of the CSV file (including the extension).\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "\n",
    "        \n",
    "        # Save the DataFrame to CSV\n",
    "        df.to_feather(path_to_file)\n",
    "    \n",
    "\n",
    "    def fetch_movie_details_from_api(self,tmdb_id):\n",
    "        movie_url = f'{self.config.source_URL}{tmdb_id}?api_key={API_KEY}'\n",
    "        credits_url = f'{self.config.source_URL}{tmdb_id}/credits?api_key={API_KEY}'\n",
    "        keywords_url = f'{self.config.source_URL}{tmdb_id}/keywords?api_key={API_KEY}'\n",
    "\n",
    "        movie_data = {}\n",
    "\n",
    "        try:\n",
    "            with request.urlopen(movie_url) as response:\n",
    "                movie_data = json.loads(response.read().decode('utf-8'))\n",
    "\n",
    "            with request.urlopen(credits_url) as response:\n",
    "                credits_data = json.loads(response.read().decode('utf-8'))\n",
    "                crew = credits_data.get('crew', [])\n",
    "                director = next((member['name'] for member in crew if member.get('job') == 'Director'), np.nan)\n",
    "                movie_data['director'] = director\n",
    "\n",
    "            with request.urlopen(keywords_url) as response:\n",
    "                keywords_data = json.loads(response.read().decode('utf-8'))\n",
    "                keywords = [keyword['name'] for keyword in keywords_data.get('keywords', [])]\n",
    "                movie_data['keywords'] = keywords\n",
    "\n",
    "        except urllib.error.HTTPError as e:\n",
    "            logger.info(f'Error occurred while requesting movie data {tmdb_id}:', e.code)\n",
    "\n",
    "        return movie_data\n",
    "\n",
    "    def fetch_batch_movie_details(self,tmdb_ids):\n",
    "        movie_data_list = []\n",
    "        for tmdb_id in tmdb_ids:\n",
    "            cache_file = Path(os.path.join(self.config.cache_dir, f'{tmdb_id}.json'))\n",
    "\n",
    "            try:\n",
    "                with open(cache_file, 'r') as file:\n",
    "                    movie_data = json.load(file)\n",
    "            except FileNotFoundError:\n",
    "                # If the cache file does not exist, fetch the movie details from the API\n",
    "                movie_data = self.fetch_movie_details_from_api(tmdb_id)\n",
    "                # Cache the movie details\n",
    "                with open(cache_file, 'w') as file:\n",
    "                    json.dump(movie_data, file)\n",
    "            \n",
    "\n",
    "            movie_data_list.append(movie_data)\n",
    "        \n",
    "\n",
    "        return movie_data_list\n",
    "\n",
    "\n",
    "    def get_movie_details(self,tmdb_id):\n",
    "        cache_file = Path(os.path.join(self.config.cache_dir, f'{tmdb_id}.json'))\n",
    "        try:\n",
    "            with open(cache_file, 'r') as file:\n",
    "                movie_data = json.load(file)\n",
    "        except FileNotFoundError:\n",
    "            # If the cache file does not exist, fetch the movie details from the API\n",
    "            movie_data = self.fetch_movie_details_from_api(tmdb_id)\n",
    "            # Cache the movie details\n",
    "            with open(cache_file, 'w') as file:\n",
    "                json.dump(movie_data, file)\n",
    "\n",
    "        # Extract the desired fields from the movie data\n",
    "        genres = [genre['name'] for genre in movie_data.get('genres', [])]\n",
    "        overview = movie_data.get('overview', '')\n",
    "        popularity = movie_data.get('popularity', 0)\n",
    "        poster_path = movie_data.get('poster_path', '')\n",
    "        vote_average = movie_data.get('vote_average', 0)\n",
    "        vote_count = movie_data.get('vote_count', 0)\n",
    "        director = movie_data.get('director', np.nan)\n",
    "        keywords = movie_data.get('keywords', np.nan)\n",
    "\n",
    "        data = {\n",
    "            \"genres\": genres,\n",
    "            \"overview\": overview,\n",
    "            \"popularity\": popularity,\n",
    "            \"poster_path\": poster_path,\n",
    "            \"vote_average\": vote_average,\n",
    "            \"vote_count\": vote_count,\n",
    "            \"director\": director,\n",
    "            \"keywords\": keywords\n",
    "        }\n",
    "\n",
    "        return data\n",
    "\n",
    "    def get_batch_movie_details(self,tmdb_ids):\n",
    "\n",
    "        movie_data_list = self.fetch_batch_movie_details(tmdb_ids)\n",
    "\n",
    "        result = []\n",
    "        for movie_data in movie_data_list:\n",
    "            try:\n",
    "                tmdb_id = movie_data['id']\n",
    "            except KeyError:\n",
    "                tmdb_id = None\n",
    "            data = self.get_movie_details(tmdb_id)\n",
    "            result.append(data)\n",
    "        return result\n",
    "\n",
    "    ## STEPS \n",
    "    def load_data_from_db(self):\n",
    "        self.movies_df = self.get_df(data_path = self.config.movies_data)\n",
    "        self.links_df = self.get_df(data_path = self.config.links_data)\n",
    "        self.ratings_df = self.get_df(data_path = self.config.ratings_data)\n",
    "        logger.info( f'Data loaded from DB' )\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        self.links_movie_df = self.movies_df.merge(self.links_df, on='movieId')\n",
    "        # drop NAN values\n",
    "        self.links_movie_df.dropna(inplace=True, axis = 0)\n",
    "        # change tmdb type from float to int\n",
    "        self.links_movie_df['tmdbId'] = self.links_movie_df['tmdbId'].astype(int)\n",
    "        # drop timestamp from ratings_df\n",
    "        self.ratings_df.drop(columns='timestamp', inplace=True)\n",
    "        logger.info( f'Data preprocessed' )\n",
    "\n",
    "\n",
    "    def get_data_from_tmdb(self):\n",
    "        self.tmdb_ids = self.links_movie_df.tmdbId.values\n",
    "        self.movie_data = self.get_batch_movie_details(tmdb_ids = self.tmdb_ids)\n",
    "        logger.info( f'Data loaded from TMDB' )\n",
    "\n",
    "    def prepare_final_data(self):\n",
    "        self.tmdb_df = pd.DataFrame(self.movie_data)\n",
    "        # merge tmdb data and links_movie data\n",
    "        self.links_movie_df_merged = pd.merge(self.links_movie_df, self.tmdb_df, left_index=True, right_index=True)\n",
    "        # drop NAN values\n",
    "        self.links_movie_df_merged.dropna(axis = 0, inplace=True)\n",
    "        # this will create 2 separate genres, we will drop one of them\n",
    "        self.links_movie_df_merged.drop(labels='genres_x', axis=1, inplace=True)\n",
    "        # rename the other genres column\n",
    "        self.links_movie_df_merged.rename(columns = {'genres_y': 'genres'}, inplace=True)\n",
    "        # self.final_df = self.links_movie_df_merged.merge(self.ratings_df, on='movieId')\n",
    "        # # Convert float64 columns to float32\n",
    "        # float_columns = ['popularity', 'vote_average', 'rating']\n",
    "        # self.final_df[float_columns] = self.final_df[float_columns].astype('float32')\n",
    "\n",
    "        # # Convert int64 columns to int32\n",
    "        # int_columns = ['movieId', 'imdbId', 'tmdbId', 'vote_count', 'userId']\n",
    "        # self.final_df[int_columns] = self.final_df[int_columns].astype('int32')\n",
    "\n",
    "        # Define the desired column order\n",
    "        # column_order = ['movieId', 'imdbId', 'tmdbId', 'title', \n",
    "        #                 'genres', 'director', 'overview',\n",
    "        #         'vote_average', 'vote_count', 'popularity', \n",
    "        #         'keywords', 'userId', 'rating', 'poster_path']\n",
    "        # self.final_df = self.reindex_columns(self.final_df, column_order)\n",
    "        logger.info( f'Final data prepared' )\n",
    "\n",
    "    def save_final_data_in_db(self):\n",
    "        self.save_dataframe_to_csv(self.ratings_df,self.config.ratings_data_path)\n",
    "        self.save_dataframe_to_csv(self.links_movie_df_merged,self.config.movies_data_path)\n",
    "        # self.save_dataframe_to_feather(self.final_df, self.config.final_data_path)\n",
    "        unique_genres_list = self.unique_genres(self.links_movie_df_merged)\n",
    "        with open(self.config.unique_category_path, 'w') as file:\n",
    "            json.dump(unique_genres_list, file)\n",
    "\n",
    "        logger.info(f\"Unique genres saved successfully as '{self.config.unique_category_path}'.\")\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-06-27 18:17:19,610: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2023-06-27 18:17:19,614: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2023-06-27 18:17:19,616: INFO: common: created directory at: artifacts]\n",
      "[2023-06-27 18:17:19,619: INFO: common: created directory at: artifacts\\data_preparation]\n",
      "[2023-06-27 18:17:19,621: INFO: common: created directory at: artifacts\\data_preparation\\cached_data]\n",
      "[2023-06-27 18:17:19,623: INFO: common: created directory at: artifacts\\data_preparation\\final_data]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'artifacts\\\\data_ingestion\\\\ml-latest\\\\movies.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m     data_preparation\u001b[39m.\u001b[39msave_final_data_in_db()    \n\u001b[0;32m     10\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m---> 11\u001b[0m     \u001b[39mraise\u001b[39;00m e\n",
      "Cell \u001b[1;32mIn[8], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m data_preparation_config \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39mget_data_preparation_config()\n\u001b[0;32m      4\u001b[0m data_preparation \u001b[39m=\u001b[39m DataPreparation(config\u001b[39m=\u001b[39mdata_preparation_config)\n\u001b[1;32m----> 5\u001b[0m data_preparation\u001b[39m.\u001b[39;49mload_data_from_db()\n\u001b[0;32m      6\u001b[0m data_preparation\u001b[39m.\u001b[39mpreprocess_data()\n\u001b[0;32m      7\u001b[0m data_preparation\u001b[39m.\u001b[39mget_data_from_tmdb()\n",
      "Cell \u001b[1;32mIn[7], line 273\u001b[0m, in \u001b[0;36mDataPreparation.load_data_from_db\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_data_from_db\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 273\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmovies_df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_df(data_path \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig\u001b[39m.\u001b[39;49mmovies_data)\n\u001b[0;32m    274\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinks_df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_df(data_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mlinks_data)\n\u001b[0;32m    275\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mratings_df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_df(data_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mratings_data)\n",
      "Cell \u001b[1;32mIn[7], line 15\u001b[0m, in \u001b[0;36mDataPreparation.get_df\u001b[1;34m(self, data_path)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_df\u001b[39m(\u001b[39mself\u001b[39m, data_path):\n\u001b[0;32m      6\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39m    Read a CSV file into a pandas DataFrame.\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39m        pandas.DataFrame: DataFrame containing the data from the CSV file.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(data_path)\n\u001b[0;32m     16\u001b[0m     \u001b[39mreturn\u001b[39;00m df\n",
      "File \u001b[1;32mc:\\Users\\abhis\\Anaconda3\\envs\\movie_reco\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\abhis\\Anaconda3\\envs\\movie_reco\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\abhis\\Anaconda3\\envs\\movie_reco\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Users\\abhis\\Anaconda3\\envs\\movie_reco\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1662\u001b[0m     f,\n\u001b[0;32m   1663\u001b[0m     mode,\n\u001b[0;32m   1664\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1665\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1666\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1667\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1668\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1669\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1670\u001b[0m )\n\u001b[0;32m   1671\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\abhis\\Anaconda3\\envs\\movie_reco\\lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    862\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    863\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    864\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'artifacts\\\\data_ingestion\\\\ml-latest\\\\movies.csv'"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_preparation_config = config.get_data_preparation_config()\n",
    "    data_preparation = DataPreparation(config=data_preparation_config)\n",
    "    data_preparation.load_data_from_db()\n",
    "    data_preparation.preprocess_data()\n",
    "    data_preparation.get_data_from_tmdb()\n",
    "    data_preparation.prepare_final_data()\n",
    "    data_preparation.save_final_data_in_db()    \n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_data = pd.read_feather('artifacts/data_preparation/final_data/final_data.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>imdbId</th>\n",
       "      <th>tmdbId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>director</th>\n",
       "      <th>overview</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>popularity</th>\n",
       "      <th>keywords</th>\n",
       "      <th>userId</th>\n",
       "      <th>rating</th>\n",
       "      <th>poster_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>114709</td>\n",
       "      <td>862</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>[Animation, Adventure, Family, Comedy]</td>\n",
       "      <td>John Lasseter</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16771</td>\n",
       "      <td>101.402</td>\n",
       "      <td>[martial arts, jealousy, friendship, bullying,...</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>/uXDfjJbdP4ijW5hWSBrPrlKpxab.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>114709</td>\n",
       "      <td>862</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>[Animation, Adventure, Family, Comedy]</td>\n",
       "      <td>John Lasseter</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16771</td>\n",
       "      <td>101.402</td>\n",
       "      <td>[martial arts, jealousy, friendship, bullying,...</td>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>/uXDfjJbdP4ijW5hWSBrPrlKpxab.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>114709</td>\n",
       "      <td>862</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>[Animation, Adventure, Family, Comedy]</td>\n",
       "      <td>John Lasseter</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16771</td>\n",
       "      <td>101.402</td>\n",
       "      <td>[martial arts, jealousy, friendship, bullying,...</td>\n",
       "      <td>14</td>\n",
       "      <td>4.5</td>\n",
       "      <td>/uXDfjJbdP4ijW5hWSBrPrlKpxab.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>114709</td>\n",
       "      <td>862</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>[Animation, Adventure, Family, Comedy]</td>\n",
       "      <td>John Lasseter</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16771</td>\n",
       "      <td>101.402</td>\n",
       "      <td>[martial arts, jealousy, friendship, bullying,...</td>\n",
       "      <td>15</td>\n",
       "      <td>4.0</td>\n",
       "      <td>/uXDfjJbdP4ijW5hWSBrPrlKpxab.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>114709</td>\n",
       "      <td>862</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>[Animation, Adventure, Family, Comedy]</td>\n",
       "      <td>John Lasseter</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16771</td>\n",
       "      <td>101.402</td>\n",
       "      <td>[martial arts, jealousy, friendship, bullying,...</td>\n",
       "      <td>22</td>\n",
       "      <td>4.0</td>\n",
       "      <td>/uXDfjJbdP4ijW5hWSBrPrlKpxab.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId  imdbId  tmdbId             title  \\\n",
       "0        1  114709     862  Toy Story (1995)   \n",
       "1        1  114709     862  Toy Story (1995)   \n",
       "2        1  114709     862  Toy Story (1995)   \n",
       "3        1  114709     862  Toy Story (1995)   \n",
       "4        1  114709     862  Toy Story (1995)   \n",
       "\n",
       "                                   genres       director  \\\n",
       "0  [Animation, Adventure, Family, Comedy]  John Lasseter   \n",
       "1  [Animation, Adventure, Family, Comedy]  John Lasseter   \n",
       "2  [Animation, Adventure, Family, Comedy]  John Lasseter   \n",
       "3  [Animation, Adventure, Family, Comedy]  John Lasseter   \n",
       "4  [Animation, Adventure, Family, Comedy]  John Lasseter   \n",
       "\n",
       "                                            overview  vote_average  \\\n",
       "0  Led by Woody, Andy's toys live happily in his ...           8.0   \n",
       "1  Led by Woody, Andy's toys live happily in his ...           8.0   \n",
       "2  Led by Woody, Andy's toys live happily in his ...           8.0   \n",
       "3  Led by Woody, Andy's toys live happily in his ...           8.0   \n",
       "4  Led by Woody, Andy's toys live happily in his ...           8.0   \n",
       "\n",
       "   vote_count  popularity                                           keywords  \\\n",
       "0       16771     101.402  [martial arts, jealousy, friendship, bullying,...   \n",
       "1       16771     101.402  [martial arts, jealousy, friendship, bullying,...   \n",
       "2       16771     101.402  [martial arts, jealousy, friendship, bullying,...   \n",
       "3       16771     101.402  [martial arts, jealousy, friendship, bullying,...   \n",
       "4       16771     101.402  [martial arts, jealousy, friendship, bullying,...   \n",
       "\n",
       "   userId  rating                       poster_path  \n",
       "0       4     4.0  /uXDfjJbdP4ijW5hWSBrPrlKpxab.jpg  \n",
       "1      10     5.0  /uXDfjJbdP4ijW5hWSBrPrlKpxab.jpg  \n",
       "2      14     4.5  /uXDfjJbdP4ijW5hWSBrPrlKpxab.jpg  \n",
       "3      15     4.0  /uXDfjJbdP4ijW5hWSBrPrlKpxab.jpg  \n",
       "4      22     4.0  /uXDfjJbdP4ijW5hWSBrPrlKpxab.jpg  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_URL = \"https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ml-latest-small'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_URL.split('/')[-1].split('.zip')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "movies",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
